# Common Django template for GeoNode and Celery services below
x-common-django: &default-common-django
  image: ghcr.io/centrogeo/sigic-geonode-wrapper/sigic_geonode:${SIGIC_GEONODE_BASE_IMAGE_VERSION}
  build:
    context: ./geonode
    dockerfile: Dockerfile
  restart: unless-stopped
  env_file:
    - .env
  volumes:
    - statics:/mnt/volumes/statics
    - geoserver-data-dir:/geoserver_data/data
    - backup-restore:/backup_restore
    - data:/data
    - tmp:/tmp
    - uploaded-ia:/mnt/volumes/statics/uploaded/ia
    # - ./django-geonode-mapstore-client:/usr/src/django-geonode-mapstore-client
  depends_on:
    db:
      condition: service_healthy

services:
  # Our custom django application. It includes GeoNode.
  django:
    profiles: ["geonode"]
    <<: *default-common-django
    container_name: django4${COMPOSE_PROJECT_NAME}
    healthcheck:
      test: "curl -m 10 --fail --silent --write-out 'HTTP CODE : %{http_code}\n' --output /dev/null http://django:8000/"
      start_period: 60s
      interval: 60s
      timeout: 30s
      retries: 4
    environment:
      - IS_CELERY=False
    entrypoint: ["/usr/src/sigic_geonode/entrypoint.sh"]
    command: "uwsgi --ini /usr/src/sigic_geonode/uwsgi.ini"
    networks:
      - sigicnetwork

  # Celery worker that executes celery tasks created by Django.
  celery:
    profiles: ["geonode"]
    <<: *default-common-django
    container_name: celery4${COMPOSE_PROJECT_NAME}
    depends_on:
      django:
        condition: service_healthy
    environment:
      - IS_CELERY=True
    entrypoint: ["/usr/src/sigic_geonode/entrypoint.sh"]
    command: "celery-cmd"
    networks:
      - sigicnetwork

  # Nginx is serving django static and media files and proxies to django and geonode
  nginx:
    profiles: ["core", "geonode", "nginx"]
    platform: linux/amd64
    image: ghcr.io/centrogeo/sigic-geonode-wrapper/sigic_nginx:${NGINX_BASE_IMAGE_VERSION}
    build:
      context: ./geonode/docker/nginx
      dockerfile: Dockerfile
      args:
        BASE_IMAGE_VERSION: ${NGINX_BASE_IMAGE_VERSION}
    container_name: nginx4${COMPOSE_PROJECT_NAME}
    env_file:
      - .env
    environment:
      - RESOLVER=127.0.0.11
    ports:
      - "${HTTP_PORT}:80"
      - "${HTTPS_PORT}:443"
    volumes:
      - nginx-confd:/etc/nginx
      - nginx-certificates:/geonode-certificates
      - statics:/mnt/volumes/statics
      - ${ENABLE_OIDC_PROXY:+./overrides/nginx/z-keycloak-proxy.conf:/etc/nginx/sites-enabled/z-keycloak-proxy.conf:ro}
      - ${ENABLE_ADMIN_PROXY:+./overrides/nginx/z-frontend-admin.conf:/etc/nginx/sites-enabled/z-frontend-admin.conf:ro}
      - ${ENABLE_APP_PROXY:+./overrides/nginx/z-frontend-app.conf:/etc/nginx/sites-enabled/z-frontend-app.conf:ro}
      - ${ENABLE_IA_PROXY:+./overrides/nginx/z-ia-proxy.conf:/etc/nginx/sites-enabled/z-ia-proxy.conf:ro}

    restart: unless-stopped
    networks:
      - sigicnetwork

  # memcached service
  memcached:
    profiles: ["geonode"]
    image: memcached:alpine
    container_name: memcached4${COMPOSE_PROJECT_NAME}
    command: memcached ${MEMCACHED_OPTIONS}
    restart: on-failure
    healthcheck:
      test: nc -z 127.0.0.1 11211
      interval: 30s
      timeout: 30s
      retries: 5
      start_period: 30s
    networks:
      - sigicnetwork

  # Gets and installs letsencrypt certificates
  letsencrypt:
    profiles: ["https"]
    platform: linux/amd64
    image: ghcr.io/centrogeo/sigic-geonode-wrapper/sigic_letsencrypt:${LETSENCRYPT_BASE_IMAGE_VERSION}
    build:
      context: ./geonode/docker/letsencrypt
      dockerfile: Dockerfile
      args:
        BASE_IMAGE_VERSION: ${LETSENCRYPT_BASE_IMAGE_VERSION}
    container_name: letsencrypt4${COMPOSE_PROJECT_NAME}
    env_file:
      - .env
    volumes:
      - nginx-certificates:/geonode-certificates
    restart: unless-stopped
    networks:
      - sigicnetwork

  # GeoServer backend
  geoserver:
    profiles: ["geonode"]
    platform: linux/amd64
    image: ghcr.io/centrogeo/sigic-geonode-wrapper/sigic_geoserver:${GEOSERVER_BASE_IMAGE_VERSION}
    build:
      context: ./geonode/docker/geoserver
      dockerfile: Dockerfile
      args:
        BASE_IMAGE_VERSION: ${GEOSERVER_BASE_IMAGE_VERSION}
    container_name: geoserver4${COMPOSE_PROJECT_NAME}
    healthcheck:
      test: "curl -m 10 --fail --silent --write-out 'HTTP CODE : %{http_code}\n' --output /dev/null http://geoserver:8080/geoserver/ows"
      start_period: 60s
      interval: 60s
      timeout: 30s
      retries: 2
    env_file:
      - .env
    ports:
      - "8080:8080"
    volumes:
      - statics:/mnt/volumes/statics
      - geoserver-data-dir:/geoserver_data/data
      - backup-restore:/backup_restore
      - data:/data
      - tmp:/tmp
    restart: unless-stopped
    depends_on:
      data-dir-conf:
        condition: service_healthy
      django:
        condition: service_healthy
    networks:
      - sigicnetwork

  data-dir-conf:
    profiles: ["geonode"]
    image: ghcr.io/centrogeo/sigic-geonode-wrapper/sigic_geoserver_data:${GEOSERVER_DATA_BASE_IMAGE_VERSION}
    platform: linux/amd64
    build:
      context: ./geonode/docker/geoserver_data
      dockerfile: Dockerfile
      args:
        BASE_IMAGE_VERSION: ${GEOSERVER_DATA_BASE_IMAGE_VERSION}
    container_name: gsconf4${COMPOSE_PROJECT_NAME}
    entrypoint: sleep infinity
    volumes:
      - geoserver-data-dir:/geoserver_data/data
    restart: unless-stopped
    healthcheck:
      test: "ls -A '/geoserver_data/data' | wc -l"
    networks:
      - sigicnetwork

  # PostGIS database.
  db:
    profiles: ["core", "geonode", "ia", "ia-db"]
    platform: linux/amd64
    image: ghcr.io/centrogeo/sigic-geonode-wrapper/sigic_postgresql:${POSTGRES_BASE_IMAGE_VERSION}
    build:
      context: ./geonode/docker/postgresql
      dockerfile: Dockerfile
      args:
        BASE_IMAGE_VERSION: ${POSTGRES_BASE_IMAGE_VERSION}
    command: postgres -c "max_connections=${POSTGRESQL_MAX_CONNECTIONS}"
    container_name: db4${COMPOSE_PROJECT_NAME}
    env_file:
      - .env
    volumes:
      - dbdata:/var/lib/postgresql/data
      - dbbackups:/pg_backups
    restart: unless-stopped
    healthcheck:
      test: "pg_isready -d postgres -U postgres"
    ports:
      - "5432:5432"
    expose:
      - "5432"
    networks: [sigicnetwork]

  # Extra initialization for Keycloak database objects
  init-keycloak-db:
    profiles: ["oidc"]
    image: ghcr.io/centrogeo/sigic-geonode-wrapper/sigic_postgresql:${POSTGRES_BASE_IMAGE_VERSION}
    depends_on:
      db:
        condition: service_healthy
    networks:
      - sigicnetwork
    environment:
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      ENABLE_OIDC_PROXY: ${ENABLE_OIDC_PROXY}
    volumes:
      - ./scripts/init_keycloak_db.sh:/init_keycloak_db.sh:ro
    entrypoint: ["/bin/bash", "/init_keycloak_db.sh"]
    restart: "no"

  # Extra initialization for Keycloak database objects
  init-ia-db:
    profiles: ["ia", "ia-db"]
    image: ghcr.io/centrogeo/sigic-geonode-wrapper/sigic_postgresql:${POSTGRES_BASE_IMAGE_VERSION}
    depends_on:
      db:
        condition: service_healthy
    networks:
      - sigicnetwork
    environment:
      ENABLE_IA_DB: True
      DB_NAME: ${IA_DJANGO_DB_NAME}
      DB_USER: ${POSTGRES_USER}
      DB_PASSWORD: ${POSTGRES_PASSWORD}
      DB_HOST: ${DATABASE_HOST}
      DB_PORT: ${DATABASE_PORT}
      IA_USER: ${IA_DJANGO_DB_USER:-iauser}
      IA_PASSWORD: ${IA_DJANGO_DB_PASSWORD}
    volumes:
      - ./scripts/init_ia_db.sh:/init_ia_db.sh:ro
    entrypoint: [ "/bin/bash", "/init_ia_db.sh" ]
    restart: "no"

  # Vanilla RabbitMQ service. This is needed by celery
  rabbitmq:
    profiles: ["geonode"]
    image: rabbitmq:3-alpine
    container_name: rabbitmq4${COMPOSE_PROJECT_NAME}
    volumes:
      - rabbitmq:/var/lib/rabbitmq
    restart: unless-stopped
    networks:
      - sigicnetwork

  # Keycloak OIDC server
  keycloak:
    profiles: ["oidc"]
    image: ghcr.io/centrogeo/sigic-keycloak/keycloak:${KEYCLOAK_BASE_IMAGE_VERSION}
    build:
      context: ./keycloak/keycloak
      dockerfile: Dockerfile
    container_name: keycloak4${COMPOSE_PROJECT_NAME}
    restart: unless-stopped
    expose:
      - "8080"
    env_file:
      - .env
    depends_on:
      init-keycloak-db:
        condition: service_completed_successfully
    environment:
      KC_CACHE: local
      KC_DB: postgres
      KC_DB_URL_HOST: ${KC_DB_URL_HOST}
      KC_DB_URL_DATABASE: ${KC_DB_URL_DATABASE}
      KC_DB_USERNAME: ${KC_DB_USERNAME}
      KC_DB_PASSWORD: ${KC_DB_PASSWORD}
      KC_HOSTNAME: ${KC_HOSTNAME}
      KC_PROXY_HEADERS: xforwarded
      KC_HOSTNAME_STRICT: ${KC_HOSTNAME_STRICT:-true}
      KC_HTTP_RELATIVE_PATH: ${KC_HTTP_RELATIVE_PATH:-/iam}
      KC_HTTP_MANAGEMENT_RELATIVE_PATH: ${KC_HTTP_MANAGEMENT_RELATIVE_PATH:-/iam}
      KC_HTTP_ENABLED: true
      VIRTUAL_HOST: ${KC_HOSTNAME}
      VIRTUAL_PORT: 8080
      JGROUPS_DISCOVERY_PROTOCOL: DNS_PING
      JGROUPS_DISCOVERY_PROPERTIES: "dns_query=localhost"
    volumes:
      - keycloak_data:/opt/keycloak/data
    networks: [sigicnetwork]

  # Frontend for admin users
  frontend-admin:
    profiles: ["frontend-admin"]
    image: ${COMPOSE_PROJECT_NAME}/frontend-admin:latest
    build:
      context: ./frontend
      dockerfile: Dockerfile
      args:
        NODE_ENV: production
        IS_NUXT_SUBMODULE: true
        NUXT_PUBLIC_APP_BASE_PATH: /admin/
        NUXT_APP_BASE_PATH: /admin/
        NUXT_PUBLIC_AUTH_BASE_URL: ${NGINX_BASE_URL}/admin/api/auth
        NUXT_PUBLIC_BASE_URL: ${NGINX_BASE_URL}
    container_name: fendadmin4${COMPOSE_PROJECT_NAME}
    restart: unless-stopped
    env_file:
      - .env
    ports:
      - "3001:3000"
    expose:
      - "3000"
    environment:
      NODE_ENV: production
      NUXT_PUBLIC_BASE_URL: ${NGINX_BASE_URL}
      NUXT_PUBLIC_GEONODE_URL: ${NGINX_BASE_URL}
      NUXT_PUBLIC_GEONODE_API: ${NGINX_BASE_URL}/api/v2
      NUXT_PUBLIC_GEOSERVER_URL: ${NGINX_BASE_URL}/gs
      NUXT_PUBLIC_IA_BACKEND_URL: ${IA_BACKEND_URL}
      NUXT_PUBLIC_DEFAULT_PAGE: /
      NUXT_PUBLIC_GEONODE_API_DEFAULT_FILTER: ''
      NUXT_AUTH_ORIGIN: ${NUXT_AUTH_ORIGIN}
      NUXT_PUBLIC_AUTH_BASE_URL: ${NGINX_BASE_URL}/admin/api/auth
      KEYCLOAK_ISSUER: ${SOCIALACCOUNT_OIDC_ID_TOKEN_ISSUER}
      NUXT_PUBLIC_ENABLE_AUTH: true
      NUXT_PUBLIC_ENABLE_CATALOGO_VISTA: true
      NUXT_PUBLIC_ENABLE_CATALOGO_CARGA: true
      NUXT_PUBLIC_ENABLE_CONSULTA: true
      NUXT_PUBLIC_ENABLE_IAA: true
      KEYCLOAK_CLIENT_ID: ${ADMIN_KEYCLOAK_CLIENT_ID}
      KEYCLOAK_CLIENT_SECRET: ${ADMIN_KEYCLOAK_CLIENT_SECRET}
      NUXT_AUTH_SECRET: ${ADMIN_NUXT_AUTH_SECRET}
      NUXT_PUBLIC_APP_BASE_PATH: /admin/
      NUXT_APP_BASE_PATH: /admin/
      NUXT_PUBLIC_OLLAMA_MODEL: "${OLLAMA_MODEL:-deepseek-r1}"
    networks: [sigicnetwork]

  # Frontend for end users
  frontend-app:
    profiles: ["frontend-app"]
    image: ${COMPOSE_PROJECT_NAME}/frontend-app:latest
    build:
      context: ./frontend
      dockerfile: Dockerfile
      args:
        NODE_ENV: production
        IS_NUXT_SUBMODULE: true
        NUXT_PUBLIC_APP_BASE_PATH: /app/
        NUXT_APP_BASE_PATH: /app/
        NUXT_PUBLIC_AUTH_BASE_URL: ${NGINX_BASE_URL}/app/api/auth
        NUXT_PUBLIC_BASE_URL: ${NGINX_BASE_URL}
    container_name: fendapp4${COMPOSE_PROJECT_NAME}
    restart: unless-stopped
    env_file:
      - .env
    ports:
      - "3002:3000"
    expose:
      - "3000"
    environment:
      NODE_ENV: production
      NUXT_PUBLIC_BASE_URL: ${NGINX_BASE_URL}
      NUXT_PUBLIC_GEONODE_URL: ${NGINX_BASE_URL}
      NUXT_PUBLIC_GEONODE_API: ${NGINX_BASE_URL}/api/v2
      NUXT_PUBLIC_GEOSERVER_URL: ${NGINX_BASE_URL}/gs
      NUXT_PUBLIC_IA_BACKEND_URL: ${IA_BACKEND_URL}
      NUXT_PUBLIC_DEFAULT_PAGE: /
      NUXT_PUBLIC_GEONODE_API_DEFAULT_FILTER: ''
      NUXT_AUTH_ORIGIN: ${NUXT_AUTH_ORIGIN}
      NUXT_PUBLIC_AUTH_BASE_URL: ${NGINX_BASE_URL}/app/api/auth
      KEYCLOAK_ISSUER: ${NGINX_BASE_URL}/iam/realms/sigic
      NUXT_PUBLIC_ENABLE_AUTH: false
      NUXT_PUBLIC_ENABLE_CATALOGO_VISTA: false
      NUXT_PUBLIC_ENABLE_CATALOGO_CARGA: false
      NUXT_PUBLIC_ENABLE_CONSULTA: true
      NUXT_PUBLIC_ENABLE_IAA: false
      KEYCLOAK_CLIENT_ID: ${APP_KEYCLOAK_CLIENT_ID}
      KEYCLOAK_CLIENT_SECRET: ${APP_KEYCLOAK_CLIENT_SECRET}
      NUXT_AUTH_SECRET: ${APP_NUXT_AUTH_SECRET}
      NUXT_PUBLIC_APP_BASE_PATH: /app/
      NUXT_APP_BASE_PATH: /app/
      NUXT_PUBLIC_OLLAMA_MODEL: "${OLLAMA_MODEL:-deepseek-r1}"
    networks: [sigicnetwork]

  # Redis service for IA engine and queue
  redis:
    profiles: ["ia", "ia-lb"]
    image: redis:latest
    container_name: redis4${COMPOSE_PROJECT_NAME}
    expose:
      - "6379"
    networks: [sigicnetwork]

  # IA Engine service
  ia-engine:
    profiles: ["ia", "ia-engine"]
    image: ${COMPOSE_PROJECT_NAME}/ia-engine:latest
    build:
      context: ./ia-engine
      dockerfile: Dockerfile
      args:
        BUILD_ENV: prod
    container_name: ia-engine4${COMPOSE_PROJECT_NAME}
    expose:
      - "8000"
    depends_on:
      - db
    environment:
      SECRET_KEY: ${IA_DJANGO_SECRET_KEY}
      DB_NAME: ${IA_DJANGO_DB_NAME}
      DB_USER: ${POSTGRES_USER}
      DB_PASSWORD: ${POSTGRES_PASSWORD}
      DB_HOST: ${DATABASE_HOST}
      DB_PORT: ${DATABASE_PORT}
      IA_USER: ${IA_DJANGO_DB_USER:-iauser}
      IA_PASSWORD: ${IA_DJANGO_DB_PASSWORD}
      DJANGO_SETTINGS_MODULE: llm.settings.prod
      DJANGO_ENV: prod
      BUILD_ENV: prod
      GEONODE_SERVER: ${NGINX_BASE_URL}
      OLLAMA_PROTO: "${OLLAMA_PROTO:-http}"
      OLLAMA_HOST: "${OLLAMA_HOST:-ollama}"
      OLLAMA_PORT: "${OLLAMA_PORT:-11434}"
      OLLAMA_TIMEOUT: "${OLLAMA_PORT:-600}"
    entrypoint: sh ./scripts/entrypoint.sh
    networks: [sigicnetwork]

  # IA Queue service
  ia-queue:
    profiles: ["ia", "ia-lb"]
    image: ${COMPOSE_PROJECT_NAME}/ia-queue:latest
    build:
      context: ia-lb/redis_queue
      dockerfile: Dockerfile
    container_name: ia-queue4${COMPOSE_PROJECT_NAME}
    expose:
      - "8001"
    depends_on:
      - redis
    environment:
      REDIS_HOST: redis
      REDIS_PORT: 6379
      BALANCER_HOST: host.docker.internal
      BALANCER_PORT: 80
      NGINX_BASE_URL: ${NGINX_BASE_URL}
      JOB_TIMEOUT_SECONDS: ${IA_JOB_TIMEOUT_SECONDS:-300}
      OLLAMA_HOST: ${OLLAMA_HOST:-ollama}
      OLLAMA_PORT: ${OLLAMA_PORT:-11434}
      OLLAMA_TIMEOUT: "${OLLAMA_PORT:-600}"
    networks: [sigicnetwork]

  # IA Load Balancer service
  ia-lb:
    profiles: ["ia", "ia-lb"]
    image: ${COMPOSE_PROJECT_NAME}/ia-lb:latest
    build:
      context: ./ia-lb/nginx-conf
      dockerfile: Dockerfile
    container_name: ia-lb4${COMPOSE_PROJECT_NAME}
    depends_on:
      - ia-queue
    ports:
      - "81:80"
    expose:
      - "80"
    environment:
      REDIS_HOST: redis
      REDIS_PORT: 6379
      OIDC_CONFIG_URL: ${SOCIALACCOUNT_OIDC_ID_TOKEN_ISSUER}/.well-known/openid-configuration
      NGINX_RESOLVER: ${NGINX_RESOLVER:-127.0.0.11}
      IA_ENGINE_HOSTS: ${IA_ENGINE_HOSTS:-ia-engine:8000}
    # volumes:
    #   - /etc/resolv.conf:/etc/resolv.conf:ro
    networks: [sigicnetwork]

  # Ollama LLM service
  ollama:
    profiles: ["ollama"]
    image: ollama/ollama
    build:
      context: ./ia-engine
      dockerfile: Dockerfile.ollama
      args:
        OLLAMA_MODEL: "${OLLAMA_MODEL:-deepseek-r1:latest}"
    container_name: ollama4${COMPOSE_PROJECT_NAME}
    ports:
      - "${OLLAMA_PORT:-11434}:11434"
    expose:
      - "${OLLAMA_PORT:-11434}"
    volumes:
      - ollama-data:/root/.ollama
      # Monta el dispositivo NVIDIA solo si existe (evita error en hosts sin GPU)
      - /dev:/dev
    environment:
      OLLAMA_KEEP_ALIVE: "50m"
      OLLAMA_FLASH_ATTENTION: "${OLLAMA_FLASH_ATTENTION:-1}"
      OLLAMA_USE_GPU: "${OLLAMA_USE_GPU:-1}"
      OLLAMA_MODEL: "${OLLAMA_MODEL:-deepseek-r1:latest}"
      OLLAMA_PROTO: "${OLLAMA_PROTO:-http}"
      OLLAMA_HOST: "0.0.0.0"
      OLLAMA_PORT: "${OLLAMA_PORT:-11434}"
    deploy:
      resources:
        limits:
          memory: 12g
    restart: unless-stopped
    entrypoint: |
      sh -eu -c '
        echo "ðŸ” Verificando GPU disponible..."
        if command -v nvidia-smi >/dev/null 2>&1 && nvidia-smi -L >/dev/null 2>&1; then
          export OLLAMA_USE_GPU=1
          echo "âœ… GPU detectada"
        else
          export OLLAMA_USE_GPU=0
          echo "âš™ï¸ Ejecutando en CPU"
        fi

        echo "ðŸ Iniciando servidor Ollama..."
        echo "ðŸ”¥ Precargando modelo ${OLLAMA_MODEL}..."
        ollama run "${OLLAMA_MODEL}" "Hola mundo" >/dev/null 2>&1 || true
        exec ollama serve
      '
    networks:
      - sigicnetwork

networks:
  sigicnetwork:
    driver: bridge
    driver_opts:
      com.docker.network.driver.mtu: "1360"

volumes:
  keycloak_data:
    name: ${COMPOSE_PROJECT_NAME}-keycloak_data
  statics:
    name: ${COMPOSE_PROJECT_NAME}-geonode-statics
  nginx-confd:
    name: ${COMPOSE_PROJECT_NAME}-nginxconfd
  nginx-certificates:
    name: ${COMPOSE_PROJECT_NAME}-nginxcerts
  geoserver-data-dir:
    name: ${COMPOSE_PROJECT_NAME}-gsdatadir
  dbdata:
    name: ${COMPOSE_PROJECT_NAME}-dbdata
  dbbackups:
    name: ${COMPOSE_PROJECT_NAME}-dbbackups
  backup-restore:
    name: ${COMPOSE_PROJECT_NAME}-backup-restore
  data:
    name: ${COMPOSE_PROJECT_NAME}-data
  tmp:
    name: ${COMPOSE_PROJECT_NAME}-tmp
  rabbitmq:
    name: ${COMPOSE_PROJECT_NAME}-rabbitmq
  uploaded-ia:
    name: ${COMPOSE_PROJECT_NAME}-statics-uploaded-ia
  ollama-data:
    name: ${COMPOSE_PROJECT_NAME}-ollama_data